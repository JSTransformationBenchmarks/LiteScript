The Lexer
=========

The Lexer translates code (an array of lines) into an array of tokenized lines to be parsed.

The Lexer class acts as 
* Lexer/Tokenizer
* Token Stream (input)
* Producer Helper (output stream)

All the parts of the lexer work with "arrays" of lines.
(instead of a buffer or a large string)

The first lexer pass analyzes entire lines. 
Each line of the array is then classified with a Line Type:

    var LineTypes = {CODE:0, COMMENT:1, BLANK:2}

After, each line with type:CODE is then *Tokenized* and gets a `tokens[]` array

-------------------------
Utility

Helper methods
String shims (startsWith, endsWith)

    var util = require('./util')

/!
    
    declare debug:function

    declare on String
      startsWith,endsWith

    declare on String namespace
      splitExpressions,replaceQuoted
      spaces

    declare on Lexer
      filename,stringInterpolationChar

    declare on log
      error:function, warning:function

    declare on err
      soft, controled

!/



Token Recognition Regex Patterns
--------------------------------

Comments can be on a code line, starting with a `#` or `//`, and ending at the end of a line.
Example: `x = 1 //comment`

Comments can also be multiline, starting with starting with `/*` and ending with `*/` 

    var tokenPatterns = [['COMMENT', /^#(.*)$|^\/\/(.*)$/],

**Numbers** can be either in hex format (like `0xa5b`) or decimal/scientific format (`10`, `3.14159`, or `10.02e23`).
There is no distinction between floating point and integer numbers.

        ['NUMBER',/^0x[a-f0-9]+/i ],
        ['NUMBER',/^[0-9]+(\.[0-9]+)?(e[+-]?[0-9]+)?/i],

Strings can be either single or double quoted.

        ['STRING', /^'(?:[^'\\]|\\.)*'/],
        ['STRING', /^"(?:[^"\\]|\\.)*"/],

Regex tokens are regular expressions. The javascript producer, just passes the raw regex to JavaScript.

        ['REGEX', /^(\/(?![\s=])[^[\/\n\\]*(?:(?:\\[\s\S]|\[[^\]\n\\]*(?:\\[\s\S][^\]\n\\]*)*])[^[\/\n\\]*)*\/)([imgy]{0,4})(?!\w)/],

Whitespace is discarded by the lexer, but needs to exist to break up other tokens.
The semicolon `;` is considered whithespace, so you can keep adding it at the end of the line, 
and we will happily ignore it

        ['WHITESPACE',/^[\f\r\t\v\u00A0\u2028\u2029 ]+/],

ASSIGN are symbols triggering the assignment statements.
In LiteScript, assignment is a *statement* and not a *expression*

        ['ASSIGN',/^=/],
        ['ASSIGN',/^[\+\-\*\/]\=/ ], # = += -= *= /=

Postfix and prefix ++ and -- are considered 'LITERAL' 
They're not considered 'operators' since they do no introduce a new operand.
Postfix ++ and -- are modifiers for a variable reference

        ['LITERAL', /^(\+\+|\-\-)/],

Literals are also puctuation symbols (like `,` `[` `:`) 

        ['LITERAL',/^[\(\)\[\]\;\,\.\{\}]/],

An operator is a symbol or a word (like `=` or `+` or `and`) used to compose `Expressions`

        ['OPER', /^(no|is|isnt|not|and|but|or|in|instance|instanceof|has|bitwise|>>|<<|mod)\b/],
        ['OPER', /^(\^|\*|\/|\+|\-|\<\>|\>\=|\<\=|\>|\<|!==)/],
        ['OPER', /^[\?\:]/],

Identifiers (generally variable names), must start with a letter, `$`, or underscore.
Subsequent characters can also be numbers. Unicode characters are supported in variable names.

        ['IDENTIFIER',/^[$A-Za-z_\x7f-\uffff][$\w\x7f-\uffff]*/] ]


----------------------

The Token Class
===============

Each Token has:
* a type ('IDENTIFIER', 'STRING', 'OPER', 'NUMBER', etc),
* a `value` (parsed text)
* and the column in the source line in which the token appears

    class Token
/!
    
        properties
          type:string
          value:string
          column
*/

        method initialize(type, tokenText, column)

            me.type = type 
            me.value = tokenText or ' ' # no text is represened by ' ', since '' is 'falsey'
            me.column = column
        
        method toString()
            return "'#{me.value}'(#{me.type})"

InfoLine Class
--------------

The lexer turns each input line into a **infoLine**
A **infoLine** is a clean, tipified, indent computed, trimmed line
it has a source line number reference, and a tokens[] array if it's a CODE line

Each "infoLine" has: 
* a line "type" of: `BLANK`, `COMMENT` or `CODE` (LineTypes), 
* a tokens[] array if it's `CODE` 
* sourceLineNum: the original source line number (for SourceMap)
* indent: the line indent
* text: the line text (clean, trimmed)

    class InfoLine
/!
    
      properties
          type
          indent,sourceLineNum
          text:String
          tokens: Token array


!/

      method initialize(lexer,type,indent,text,sourceLineNum)
        me.type = type
        me.indent = indent
        me.text = text
        me.sourceLineNum = sourceLineNum

        #me.dump() #debug info

      #end InfoLine constructor

             
      method dump() # out debug info

        if me.type is LineTypes.BLANK
          debug me.sourceLineNum,"(BLANK)"
          return

        var type = ""
        if me.type is LineTypes.COMMENT
          type="COMMENT"
        else if me.type is LineTypes.CODE
          type="CODE"
        
        debug me.sourceLineNum, "#{me.indent}(#{type})", me.text
        if me.tokens
            debug('   ',me.tokens.join(' '))
            debug()


The Tokenize method
-------------------

The Infoline.tokenize() method, creates the 'tokens' array by parsing the .text 
It also replaces *Embdeded Expressions* #{} in string constants, storing the expression tokens

      method tokenize(lexer:Lexer)

        var code = me.text
        
        try

            var result=[]
            var colInx = 0

            #debug
            var msg = ""

            while colInx < code.length

              var chunk = code.slice(colInx)

This for loop will try each regular expression in `tokenPatterns` 
against the current head of the code line until one matches.

/!

              declare regex:RegExp
!/

              var match=''
              var tokenType=''
              for typeRegExpPair in tokenPatterns
                var regex = typeRegExpPair[1]
                var matches = regex.exec(chunk)
                if matches and matches[0]
                    match = matches[0]
                    tokenType = typeRegExpPair[0] 
                    break

              #end for checking patterns

If there was no match, this is a bad token and we will abort compilation here.

              if no match

                msg = "(#{lexer.filename}:#{me.sourceLineNum}:#{colInx+1}) Tokenize patterns: invalid token: #{chunk}"
                log.error msg
                log.error code


                var errPosString=''
                while errPosString.length<colInx
                    errPosString+=' '

                log.error errPosString+'^'

                var err = new Error(msg)
                err.controled = true
                raise err

              #end if

If its 'WHITESPACE' we ignore it. 

              if tokenType is 'WHITESPACE'
                null #ignore it

              else

create token 

                  var token = new Token(tokenType, match, me.indent + colInx + 1 )

If its a string constant, and it has `#|$`, process the **Interpolated Expressions**.

                  if tokenType is 'STRING' and match.length>3 and match.indexOf(lexer.stringInterpolationChar)>=1

/!

                    declare parsed:Array
!/

                    #parse the string, splitting at $ and ${...}, return array 
                    var parsed = String.splitExpressions(match, lexer.stringInterpolationChar)

                    #if the first expression starts with "(", we add `"" + ` so the parentheses
                    # can't be mis-parsed as a "function call"
                    if parsed.length and parsed[0].startsWith("(")
                      parsed.unshift('""')

                    #join expressions using +, so we have a valid composed expression, evaluating to a string.
                    var composed = new InfoLine(lexer, LineTypes.CODE, token.column, parsed.join(' + '), me.sourceLineNum  )

                    #Now we 'tokenize' the new composed expression
                    composed.tokenize(lexer)

                    #And we append the new tokens instead of the original string constant
                    result = result.concat( composed.tokens )

                  else

Else it's a single token. Add the token to result array

                    #debug
                    msg += token.toString()

                    result.push(token)

                  #end if

              #end if WITHESPACE

Advance col index into code line

              colInx += match.length

            #end while text in the line

            #debug
            #debug msg

Store tokenize result in tokens

            me.tokens = result

enhance error reporting

        catch e
            log.error msg
            throw e


--------------------------

    class LexerPos

/!

      properties
          lineInx,sourceLineNum
          index,token,last

!/

      method dummy()
        null


----------------------------------------------------------------------------------------------

The Lexer Class
===============

The Lexer class turns the input lines into an array of "infoLines"

forward declare

/!

    declare on Lexer
        nextSourceLine
        parseTripleQuotes,checkMultilineComment
        getPos,nextToken
        sayErr
        nextCODELine

!/

    class Lexer

/!

      properties 
        filename:string
        lines:string array
        infoLines: InfoLine array
        sourceLineNum
        lineInx
        line:String
        infoLine, token, last:LexerPos
        indent, index

        stringInterpolationChar, 
        errCount, hardError
        inNode

      declare on sourceMap 
          addMapping

!/
Lexer initialize: 
=================

      method initialize()

Default string interpolation char 

          me.stringInterpolationChar = '#' # can be changed later with `compiler` directive

lexer-global counters

          me.errCount = 0 #incremented each time the compiler emits a "ERROR" (not WARN - see sayErr)

          me.hardError = null # stores most significative (deepest) error, when parsing fails

empty Token
          
          me.token = new Token()
          
      #end constructor

----------

      method initSource(filename, source:String)

remember filename (for error reporting) 

          me.filename = filename

create source lines array

If code is passed as a buffer, convert it to string

          if typeof source isnt 'string'
            source = source.toString()
          
          me.lines = source.split('\n')



----------

Lexer Process:
==============
*Create infoLines[] array
*Tokenize CODE lines

      method process()

prepare processed lines result array

        me.infoLines = []

Regexp to match keywords on first column or markdown titles, and consider them CODE

        var keywRegexp = new RegExp("^(#)*(?: ){0,2}(public class|public function|class|extend class|properties$|constructor|method|function)\\b","i")
        var keywIndent = {'public class':4, 'public function':4, 'class':4, 'function':4, 'extend class':4, 'properties':6, 'constructor':6, 'method':6}

Loop processing source code lines 

        var lastLineWasBlank = true

        me.sourceLineNum = 0
        while me.nextSourceLine()

get line indent, count whitespace: (index of first non-whitespace: \S ) 
then trim() the line

            var line = me.line
            var indent = line.search(/\S/)
            line = line.trim()

LiteScript files (.lite.md) are "literate" markdown and code files.

To be considered "code", a block of lines must be indented at least four spaces. 
(see: Github Flavored MarkDown syntax)

The exception are the keywords: `public`,`class`,`function`,`constructor`,`method` and `properties` 
which can appear before column 4. Even if the keyword is preceded by MD title marks (##) 
the line still will be considered CODE.

Anything else starting on col 1, 2 or 3 is a literate comment, MD syntax.
If you start a literate comment, like this one, it will continues until a blank line is found,
that is, you need to leave a blank line before starting a indented block of code.

Now, process the lines with this rules

            if no line 

a blank line is always a blank line

                var type = LineTypes.BLANK

            else 

else, if indented 4 spaces or more, can be the start of a code block

                if indent >= 4

                    if lastLineWasBlank
                        var codeBlock = true

                else

else, (not indented) probably a literate comment

                    codeBlock = false

except for certain keywords 

                    if indent is 0 # ...on column 1

                      var found = keywRegexp.exec(line)

                      if found and found[2] # 0:full match 1:markdown#s 2:found keyword

/!
                          
                          declare foundKey:string
!/

                          var foundKey=found[2].toLowerCase() 
                          indent = keywIndent[foundKey]
                          #debug
                          if no indent
                            fail with 'compiler internals: check special keywords for col 1'

rewrite the line, removing MD title formatting (####) and making keywords lowercase

                          line = foundKey.toLowerCase() + line.slice(found[0].length)
                          codeBlock = true

                    #end if - special kws

                #end if - line, check indent

After rules: if we're in a codeBlock, is CODE, else is a COMMENT

                if codeBlock

                    if line.startsWith("#") or line.startsWith("//") # code, but all comment
                      type = LineTypes.COMMENT
                    else
                      type = LineTypes.CODE
                
                else
                    type = LineTypes.COMMENT
                #end if

            #end if line wasnt blank

parse multi-line string (triple quotes) and convert to one logical line: 
Example: var a = 'first line\nsecond line\nThat\'s all\n'

            if type is LineTypes.CODE 
              line = me.parseTripleQuotes( line )

check for multi-line comment, C and js style (/* */) 

            if me.checkMultilineComment(type, indent, line )
                continue #found and pushed multiline comment, continue with next line

Create infoLine, with computed indent, text, and source code line num reference 

            var infoLine = new InfoLine(me, type, indent, line, me.sourceLineNum )
            infoLine.dump() # debug

            me.infoLines.push( infoLine ) 

            lastLineWasBlank = type is LineTypes.BLANK
            
            

        #end loop, process next source line


Now, after processing all lines, we tokenize each CODE line

        debug "---- TOKENIZE"

        for item in me.infoLines

            item.dump() # debug
        
            if item.type is LineTypes.CODE
                item.tokenize(me)
            #end if

        #end loop code lines

now we have a infoLine array, tokenized, ready to be parsed
clear source lines from memory

        me.lines = undefined

reset Lexer position, to allow the parser to start reading tokens

        me.lineInx = -1 #line index
        me.infoLine = null #current infoLine
        me.index = -1 #token index

        me.last = me.getPos() #last position

read first token

        me.nextToken() 

    #end Lexer process


Next Source Line
----------------

      method nextSourceLine()

        if me.sourceLineNum >= me.lines.length
          return false

get source line, replace TAB with 4 spaces, remove trailing withespace and remove CR

        me.line = me.lines[me.sourceLineNum].replace(/\t/g,'    ').replace(/\s+$/,'').replace(/\r/,'')
        me.sourceLineNum += 1 # 1-based

        return true


Multiline strings
-----------------

----------------------------
This is the generic method to get a section of text between start and end codes

      method getMultilineSection(line:string, startCode:string, endCode:string)

check startCode for multiline, if not found, exit 

        var startCol = line.indexOf(startCode)
        if startCol<0 
            #no start code found
            return null

get rid of quoted strings. Still there?

        if String.replaceQuoted(line,"").indexOf(startCode)<0 
            return null #no 

found startCode, initialize

        debug "**** START MULTILINE ",startCode

        var section = []
        var startSourceLine = me.sourceLineNum

Get and save text previous to startCode

        var pre = line.slice(0, startCol).trim()

Get text after startCode

        line = line.slice(startCol+startCode.length).trim()

read lines looking for endCode

        while true

            var endCol = line.indexOf(endCode)
            if endCol>=0 #found end of section
                #get rid of quoted strings. Still there?
                if String.replaceQuoted(line,"").indexOf(endCode)>=0 
                  break

            # still inside the section
            section.push line

            if no me.nextSourceLine()
                me.sayErr "EOF while processing multiline #{startCode} (started on #{me.filename}:#{startSourceLine}:#{startCol})"
                return

            line = me.line
            
        #loop until end of section

text before endCode, goes into multiline section

        line = line.slice(0, endCol)
        if line 
          section.push line

get text after endCode (post)

        var post = line.slice(endCol + endCode.length)

        return {pre:pre, section:section, post:post}

----------------------------------------

This method handles `"""` triple quotes multiline strings
Mulitple coded-enclosed source lines are converted to one logical infoLine

Example:
/*
 var c = """
   first line
   second line
   That's all
   """.length

gets converted to:
<pre>
  var c = 'first line\nsecond line\nThat\'s all\n'.length
  ^^^^^^^   ^^^^^^^                               ^^^^^
    pre     section                                post
</pre>
*/


      method parseTripleQuotes(line:string)

        var result = me.getMultilineSection(line, '"""', '"""')

/!

        declare on result
          pre:string, section:string array, post:string

!/

        if result 

          #trim lines
          for sectionLine at inx in result.section
            result.section[inx]=sectionLine.trim()

          line = result.section.join("\\n") #join with (encoded) newline char
          line = line.replace(/'/g,"\\'") #escape quotes
          line = result.pre + " " + line.quoted("'") + result.post #add pre & post

        return line

      #end parse triple quotes

----------------------------
This method handles multiline comments: `/*` `*/` 

      method checkMultilineComment(lineType, startLineIndent, line)

        var startSourceLine = me.sourceLineNum

        var result = me.getMultilineSection(line, '/*', '*/')

/!

        declare on result
          pre:string, section:string array, post:string

!/

        if no result 
          return false

        if result.section.length is 1 # just one line
          line = result.pre + " // " + result.section[0] + result.post
          me.infoLines.push(new InfoLine(me, lineType, startLineIndent, line, startSourceLine))  

        else 
          if result.pre
            me.infoLines.push(new InfoLine(me, lineType, startLineIndent, result.pre, startSourceLine))  

          for sectionLine at inx in result.section
            me.infoLines.push(new InfoLine(me, LineTypes.COMMENT, 0, sectionLine, startSourceLine+inx))  

          if result.post 
            me.sayErr "Do not add text on the same line after `*/`. Indent is not clear"
            me.infoLines.push(new InfoLine(me, LineTypes.CODE, startLineIndent, result.post, me.sourceLineNum))  

        return true #OK, lines processed



----------------------------
Methods getPos() and setPos() are used to save and restore a specific lexer position in code
When a AST node parse() fails, the lexer position is rewound to try another AST class

      method getPos()
        return {lineInx:me.lineInx, index:me.index, sourceLineNum:me.sourceLineNum, token:me.token, last:me.last}

----------------------------

      method setPos(pos:LexerPos)

        me.lineInx = pos.lineInx

        if me.lineInx>=0 and me.lineInx<me.infoLines.length
            me.infoLine = me.infoLines[me.lineInx]
            me.indent = me.infoLine.indent
        else
            me.infoLine = null
            me.indent = 0

        me.index = pos.index
        me.sourceLineNum = pos.sourceLineNum
        me.token = pos.token
        me.last = pos.last


helper method posToString() 
Create a full string with last position. Useful to inform errors

      method posToString()

        if no me.last
            return 

        if no me.last.token
            me.last.token = {column:0}

        var col = me.last.token.column or me.infoLine.indent
        if not col or col<0
            col = 0

        return "#{me.filename}:#{me.last.sourceLineNum}:#{col}"

----------------------------
getPrevIndent() method returns the indent of the previous code line
is used in 'Parser.lite' when processing an indented block of code, 
to validate the line indents and give meaningful compiler error messages

      method getPrevIndent()
        var inx = me.lineInx-1
        while inx >=0
            if me.infoLines[inx].type is LineTypes.CODE
                return me.infoLines[inx].indent
            inx -= 1

        return 0

----------------------------------------------------
This functions allows the parser to navigate lines and tokens
of the lexer. It returns the next token, advancing the position variables.
This method returns CODE tokens, "NEWLINE" tokens (on each new line) or the "EOF" token.
All other tokens (COMMENT and WHITESPACE) are discarded.


      method consumeToken()

loop until a CODE token is found

        while true

loop until a valid CODE infoLine is selected

            me.token = null
            while true

if no line selected

                if not me.infoLine

                    me.index = -1

get next CODE line

                    if not me.nextCODELine()

if no more CODE lines -> EOF

                        me.infoLine = new InfoLine(me, LineTypes.CODE, -1, '', me.lineInx)
                        me.token = new Token('EOF')
                        me.infoLine.tokens = [me.token]
                        me.indent = -1
                        return

since we moved to the next line, return "NEWLINE" token

                    me.sourceLineNum = me.infoLine.sourceLineNum
                    me.indent = me.infoLine.indent
                    me.token = new Token('NEWLINE')
                    return

get next token in the line

                if no me.infoLine.tokens
                  debugger


                me.index += 1
                if me.index < me.infoLine.tokens.length
                    break #ok, a line with tokens

if there was no more tokens, set infoLine to null, 
and continue (get the next line)

                me.infoLine = null

            #end while

Here we have a infoLine, where type is CODE
Get the token

            me.token = me.infoLine.tokens[me.index]

if the token is a COMMENT, discard it, 
by continuing the loop (get the next token)

            if me.token.type is 'COMMENT'
                continue #discard COMMENT

if it is not a COMMENT, break the loop
returning the CODE Token in lexer.token

            else
                break #the loop, CODE token is in lexer.token

        #loop #try to get another

      #end method consumeToken

---------------------------------------------------------

      method nextToken()

Save current pos, and get next token

        me.last = me.getPos()

        me.consumeToken()

        #debug
        debug ">>>ADVANCE", me.sourceLineNum, me.index, me.token.toString()
        
        return true

-----------------------------------------------------

      method returnToken()
        #restore last saved pos (rewind)

        me.setPos me.last
        debug '<< Returned:',me.token.toString(),'line',me.sourceLineNum 

-----------------------------------------------------
This method gets the next line CODE from infoLines
BLANK and COMMENT lines are skipped.
return true if a CODE Line is found, false otherwise

      method nextCODELine()

        if me.lineInx >= me.infoLines.length
            return false # no more lines

loop until a CODE line is found

        while true

            me.lineInx += 1
            if me.lineInx >= me.infoLines.length
                return false # no more lines
Get line

            me.infoLine = me.infoLines[me.lineInx]

if it is a CODE line, store in lexer.sourceLineNum, and return true (ok)

            if me.infoLine.type is LineTypes.CODE

                me.sourceLineNum = me.infoLine.sourceLineNum
                me.indent = me.infoLine.indent
                me.index = -1

                return true #ok nextCODEline found

        #end while

      #end method


-----------------------------------------------------------------------
**say** emit error (but continue compiling)

      method say()

        me.errCount+=1
        log.error.apply(this,arguments)

      #end 


-----------------------------------------------------------------------
**throwErr** 

      method throwErr(msg)

        var err = new Error(msg)
        err.controled = true 
        throw err

      #end 

-----------------------------------------------------------------------
**sayErr** add lexer position and emit error (but continue compiling)

      method sayErr(msg)

        me.errCount+=1
        log.error(me.posToString(), msg)
        if me.errCount>10
          me.throwErr "10 errors, aborting compilation"

      #end 

------------------------
Exports
=======

    
    #make LineTypes const available as me.lexer.LineTypes
    Lexer.prototype.LineTypes = LineTypes

    Lexer.prototype.Token = Token

    Lexer.prototype.InfoLine = InfoLine

    module.exports = Lexer 
